{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab94c09c-41bc-4fca-8920-d2e7f185958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83effe5b-96c1-482b-82a0-fc11c68a44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"~/Uni-stuff/semester-2/applied_Ml/reef_zmsc\").expanduser().resolve()\n",
    "STAGE1_REL = Path(\"data/autolabeling_fixed/models/classifier.joblib\")\n",
    "STAGE2_REL = Path(\"data/two_stage_detector/models/two_stage_pipeline.joblib\")\n",
    "FEATURES_PATH = Path(\"/path/to/X.npy\").expanduser().resolve() # or .npz with key 'X'\n",
    "OUTDIR = Path(\"evaluation/consistency_reports\").resolve()\n",
    "STRENGTHS = (0.0, 0.05, 0.1, 0.2, 0.3) # 0.0 = none, 0.3 = moderate perturbation\n",
    "SEED = 42\n",
    "MAX_SAMPLES: Optional[int] = 5000 # set to None to use all rows\n",
    "\n",
    "\n",
    "# Derived paths\n",
    "STAGE1_PATH = (ROOT_DIR / STAGE1_REL).resolve()\n",
    "STAGE2_PATH = (ROOT_DIR / STAGE2_REL).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b361208-4724-4fde-9d54-5070ca2c3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(path: Path) -> np.ndarray:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Features file not found: {path}\")\n",
    "    if path.suffix == \".npy\":\n",
    "        X = np.load(path)\n",
    "    elif path.suffix == \".npz\":\n",
    "        data = np.load(path)\n",
    "        for key in (\"X\", \"features\", \"arr_0\"):\n",
    "            if key in data:\n",
    "                X = data[key]\n",
    "                break\n",
    "        else:\n",
    "            raise KeyError(\".npz missing one of keys: 'X', 'features', 'arr_0'\")\n",
    "    else:\n",
    "        raise ValueError(\"Features must be a .npy or .npz file\")\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D feature array [N, D], got {X.shape}\")\n",
    "    return X.astype(np.float32, copy=False)\n",
    "\n",
    "def safe_softmax(logits: np.ndarray) -> np.ndarray:\n",
    "    if logits.ndim != 2:\n",
    "        raise ValueError(\"logits must be [N, C]\")\n",
    "    # If already probabilities (sumâ‰ˆ1, in [0,1]) just return\n",
    "    if np.all(logits >= -1e-6) and np.all(logits <= 1 + 1e-6):\n",
    "        row_sums = logits.sum(axis=1, keepdims=True)\n",
    "        if np.allclose(row_sums, 1.0, atol=1e-3):\n",
    "            return logits\n",
    "    x = logits - logits.max(axis=1, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / (e.sum(axis=1, keepdims=True) + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128007ce-3faf-48c5-a31a-5cfd943abd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_augmentations(\n",
    "    X: np.ndarray, strength: float, rng: np.random.Generator\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Small, benign perturbations in feature space.\n",
    "    - multiplicative jitter ~ N(1, sigma)\n",
    "    - additive noise ~ N(0, sigma)\n",
    "    - low-rank tilt on a random subset of dims\n",
    "    \"\"\"\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    N, D = X.shape\n",
    "    sigma = 0.05 * strength\n",
    "\n",
    "    # multiplicative jitter\n",
    "    mul = rng.normal(1.0, sigma, size=(N, D)).astype(np.float32)\n",
    "    Y = X * mul\n",
    "\n",
    "    # additive noise\n",
    "    add = rng.normal(0.0, sigma, size=(N, D)).astype(np.float32)\n",
    "    Y = Y + add\n",
    "\n",
    "    # low-rank tilt\n",
    "    k = max(1, int(D * min(0.1, 0.4 * strength)))\n",
    "    if k > 0:\n",
    "        idx = rng.choice(D, size=k, replace=False)\n",
    "        tilt = rng.normal(0.0, sigma, size=(N, k)).astype(np.float32)\n",
    "        Y[:, idx] += tilt\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "def predict_with_model(model, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Return (y_pred, p_max). Supports sklearn-style API.\n",
    "    Falls back to decision_function -> softmax when needed.\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs = model.predict_proba(X)\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        scores = model.decision_function(X)\n",
    "        if scores.ndim == 1:\n",
    "            scores = np.stack([-scores, scores], axis=1)\n",
    "        probs = safe_softmax(scores)\n",
    "    else:\n",
    "        y = model.predict(X)\n",
    "        return y.astype(int), np.full(X.shape[0], 0.5, dtype=np.float32)\n",
    "\n",
    "    y = np.argmax(probs, axis=1).astype(int)\n",
    "    pmax = probs.max(axis=1).astype(np.float32)\n",
    "    return y, pmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e11c119-e675-4c70-99f6-01c4f5d3c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_consistency(\n",
    "    model,\n",
    "    X: np.ndarray,\n",
    "    strengths=STRENGTHS,\n",
    "    seed: int = SEED,\n",
    "    max_samples: Optional[int] = MAX_SAMPLES,\n",
    "    title_prefix: str = \"Stage1\",\n",
    "    outdir: Path | None = OUTDIR,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if max_samples is not None and X.shape[0] > max_samples:\n",
    "        sel = rng.choice(X.shape[0], size=max_samples, replace=False)\n",
    "        X = X[sel]\n",
    "\n",
    "    # Base predictions\n",
    "    y0, p0 = predict_with_model(model, X)\n",
    "\n",
    "    consistencies = []\n",
    "    all_strengths = []\n",
    "\n",
    "    for s in strengths:\n",
    "        X_aug = feature_augmentations(X, strength=s, rng=rng)\n",
    "        y1, _ = predict_with_model(model, X_aug)\n",
    "        agree = (y0 == y1)\n",
    "        cons = float(agree.mean())\n",
    "        consistencies.append(cons)\n",
    "        all_strengths.append(s)\n",
    "        print(f\"{title_prefix} | strength={s:.2f} -> consistency={cons:.4f}\")\n",
    "\n",
    "    # Plot consistency curve\n",
    "    OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(all_strengths, consistencies, marker=\"o\")\n",
    "    plt.xlabel(\"Augmentation strength (feature space)\")\n",
    "    plt.ylabel(\"Consistency (agreement rate)\")\n",
    "    plt.title(f\"{title_prefix}: Consistency vs Aug Strength\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    curve_path = OUTDIR / f\"{title_prefix.lower()}_consistency_curve.png\"\n",
    "    plt.savefig(curve_path, dpi=160, bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {curve_path}\")\n",
    "\n",
    "    # Confidence histogram at a mid strength\n",
    "    mid_idx = min(len(strengths) - 1, 2)  # pick a reasonable mid point\n",
    "    s_mid = strengths[mid_idx]\n",
    "    X_mid = feature_augmentations(X, strength=s_mid, rng=rng)\n",
    "    y_mid, _ = predict_with_model(model, X_mid)\n",
    "    agree_mid = (y0 == y_mid)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.hist(p0[agree_mid], bins=30, alpha=0.7, label=\"consistent\")\n",
    "    plt.hist(p0[~agree_mid], bins=30, alpha=0.7, label=\"inconsistent\")\n",
    "    plt.xlabel(\"Base prediction confidence (max prob)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{title_prefix}: Confidence by Consistency (s={s_mid:.2f})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    hist_path = OUTDIR / f\"{title_prefix.lower()}_confidence_hist.png\"\n",
    "    plt.savefig(hist_path, dpi=160, bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {hist_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddbd88-5313-406c-b79d-6507fb61321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Stage 1 model:\", STAGE1_PATH)\n",
    "    print(\"Two-Stage model:\", STAGE2_PATH)\n",
    "    print(\"Features:\", FEATURES_PATH)\n",
    "    print(\"Outdir:\", OUTDIR)\n",
    "\n",
    "    # Load models\n",
    "    print(\"Loading Stage 1 model...\")\n",
    "    stage1 = joblib.load(STAGE1_PATH)\n",
    "\n",
    "    stage2 = None\n",
    "    try:\n",
    "        print(\"Loading Two-Stage pipeline...\")\n",
    "        stage2 = joblib.load(STAGE2_PATH)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Could not load Two-Stage pipeline:\", e)\n",
    "\n",
    "    # Load features\n",
    "    print(\"Loading features...\")\n",
    "    X = load_features(FEATURES_PATH)\n",
    "    print(\"Features shape:\", X.shape)\n",
    "\n",
    "    # Evaluate Stage 1\n",
    "    print(\"=== Evaluating Stage 1 ===\")\n",
    "    evaluate_consistency(\n",
    "        model=stage1,\n",
    "        X=X,\n",
    "        strengths=STRENGTHS,\n",
    "        seed=SEED,\n",
    "        max_samples=MAX_SAMPLES,\n",
    "        title_prefix=\"Stage1\",\n",
    "        outdir=OUTDIR,\n",
    "    )\n",
    "\n",
    "    # Evaluate Two-Stage (optional)\n",
    "    if stage2 is not None:\n",
    "        print(\"=== Evaluating Two-Stage ===\")\n",
    "        try:\n",
    "            evaluate_consistency(\n",
    "                model=stage2,\n",
    "                X=X,\n",
    "                strengths=STRENGTHS,\n",
    "                seed=SEED,\n",
    "                max_samples=MAX_SAMPLES,\n",
    "                title_prefix=\"TwoStage\",\n",
    "                outdir=OUTDIR,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] Skipping Two-Stage evaluation:\", e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
