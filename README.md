# ğŸŒŠ Reef Acoustic Monitoring - Weakly-Supervised Soundscape Classification

<div align="center">

![Coral Reef](https://img.shields.io/badge/ğŸ -Coral_Reef_Acoustics-blue)
![ML](https://img.shields.io/badge/Machine_Learning-Weakly--Supervised-green)
![Python](https://img.shields.io/badge/Python-3.10-yellow)
![Status](https://img.shields.io/badge/Status-Research-orange)

**Automated classification of underwater reef soundscapes using machine learning**  
*No manual labeling required*

[Overview](#-overview) â€¢ [Features](#-key-features) â€¢ [Methodology](#-methodology) â€¢ [Results](#-results) â€¢ [Structure](#-project-structure)

</div>

---

## ğŸ¯ Overview

This project develops an **automated classification system** for marine acoustic data from long-term reef monitoring. Using **weakly-supervised learning**, the system identifies different soundscape typesâ€”**biological activity (BIO)**, **ambient ocean sounds (AMBIENT)**, and **anthropogenic noise (HUMAN)**â€”without requiring extensive manual annotation.

### Why This Matters

- ğŸ  **Marine Conservation**: Understand reef health through acoustic monitoring
- â±ï¸ **Scalability**: Process millions of audio clips automatically
- ğŸ’° **Cost-Effective**: No expensive manual labeling required
- ğŸ”¬ **Research Tool**: Enable long-term ecosystem monitoring

---

## âœ¨ Key Features

### ğŸµ Multi-Source Feature Extraction
- **YAMNet Embeddings** (1,024 dims) - Pre-trained deep learning features
- **Ecoacoustic Indices** (17 dims) - Domain-specific acoustic metrics
- **PCA Dimensionality Reduction** - Efficient 39-dimensional representation

### ğŸ¤– Weakly-Supervised Learning Pipeline
- **Unsupervised Clustering** - K-Means discovers natural patterns
- **Automated Pseudo-Labeling** - Rule-based heuristics assign categories
- **Two-Stage Classification** - Hierarchical AMBIENT â†’ BIO â†’ HUMAN detection

### ğŸ§ª Novel Validation Approach
- **Robustness Testing** - Perturbation-based consistency analysis
- **Ensemble Validation** - Multi-model agreement (5 architectures)
- **No ground truth required** - Confidence metrics without manual labels

---

## ğŸ”¬ Methodology

```mermaid
graph LR
    A[ğŸµ Raw Audio<br/>10s clips] --> B[ğŸ“Š Feature Extraction<br/>YAMNet + Ecoacoustic]
    B --> C[ğŸ”„ PCA<br/>1041 â†’ 39 dims]
    C --> D[ğŸ¯ K-Means Clustering<br/>K=3]
    D --> E[ğŸ·ï¸ Pseudo-Labeling<br/>Rule-based]
    E --> F[ğŸ¤– Stage 1<br/>AMBIENT vs BIO]
    F --> G[ğŸš¢ Stage 2<br/>HUMAN Detection]
    G --> H[ğŸ“ˆ Classification<br/>3 Categories]
```

### Pipeline Steps

1. **ğŸ“Š Feature Engineering**
   - Extract acoustic embeddings and indices
   - Reduce dimensionality while preserving variance

2. **ğŸ” Unsupervised Discovery**
   - Cluster audio clips by acoustic similarity
   - Compare K-Means, HDBSCAN, and GMM

3. **ğŸ·ï¸ Automated Labeling**
   - Apply acoustic ecology principles
   - Generate pseudo-labels with confidence scores

4. **ğŸ¯ Supervised Classification**
   - Train multi-stage detector on pseudo-labels
   - Validate using robustness and ensemble methods

---

## ğŸ“ˆ Results

### Model Performance

| Metric | Score | Status |
|--------|-------|--------|
| **Clustering Quality** (Silhouette) | 0.769 | âœ… Excellent separation |
| **Stage 1 Accuracy** | 99.90% | âš ï¸ Requires larger test set |
| **Robustness** | 0.998 | âœ… Stable predictions |
| **Model Agreement** | 0.999 | âœ… High consensus |

### âš ï¸ Important Notes

- Current validation on **small test set (n=20)**
- Pseudo-labels not verified against expert annotations
- Stage 2 (HUMAN detection) in development
- Comprehensive validation needed before deployment

See [detailed evaluation](Result_Evaluation.md) for full analysis.

---

## ğŸ“ Project Structure

```
reef_zmsc/
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ autolabeling_fixed/          # Pseudo-labeling results
â”‚   â”‚   â”œâ”€â”€ models/                  # Stage 1 classifier
â”‚   â”‚   â””â”€â”€ results/                 # Cluster labels
â”‚   â”‚
â”‚   â”œâ”€â”€ clustering/                  # K-Means, HDBSCAN, GMM
â”‚   â”‚   â””â”€â”€ results_50k/             # Clustered data
â”‚   â”‚
â”‚   â”œâ”€â”€ features/                    # Extracted features
â”‚   â”‚   â”œâ”€â”€ embeds_yamnet_50k/       # YAMNet embeddings
â”‚   â”‚   â”œâ”€â”€ embeds_ecoacoustic_50k/  # Ecoacoustic indices
â”‚   â”‚   â”œâ”€â”€ embeds_fused_50k/        # Combined features
â”‚   â”‚   â””â”€â”€ embeds_preprocessed_50k/ # PCA features
â”‚   â”‚
â”‚   â”œâ”€â”€ model_testing/               # Test predictions
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚
â”‚   â”œâ”€â”€ model_validation/            # Robustness & agreement tests
â”‚   â”‚
â”‚   â””â”€â”€ two_stage_detector/          # Stage 2 (HUMAN) detector
â”‚       â”œâ”€â”€ models/
â”‚       â””â”€â”€ results/
â”‚
â”œâ”€â”€ ğŸ“‚ calibration/                  # Logger calibration files
â”œâ”€â”€ ğŸ“‚ cfg/                          # Configuration files
â”œâ”€â”€ ğŸ“‚ notebooks/                    # Jupyter analysis notebooks
â”œâ”€â”€ ğŸ“‚ scripts/                      # Python scripts
â”œâ”€â”€ ğŸ“‚ wav/                          # Raw audio data (PAPCA)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     # This file
â”œâ”€â”€ ğŸ“„ Result_Evaluation.md          # Detailed validation report
â””â”€â”€ ğŸ“„ requirements.txt              # Dependencies
```


## ğŸ› ï¸ Technologies

| Category | Tools |
|----------|-------|
| **Language** | Python 3.10 |
| **ML/DL** | scikit-learn, TensorFlow, YAMNet |
| **Audio** | librosa, soundfile |
| **Data** | pandas, numpy, parquet |
| **Clustering** | K-Means, HDBSCAN, GMM |
| **Visualization** | matplotlib, seaborn |

---

## ğŸ“Š Dataset

- **Source**: Autonomous underwater acoustic recorders
- **Location**: Coral reef ecosystems (2 loggers)
- **Duration**: 271 days continuous monitoring
- **Total Clips**: 1,053,610 Ã— 10-second segments
- **Training Set**: 15,392 clips (after deduplication)

